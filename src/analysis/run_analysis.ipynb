{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f51d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of runs by framework under the runs/ directory as a pandas dataframe\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_sprints_df(runs_directory='../runs/'):\n",
    "    sprints_df = pd.DataFrame(columns=[\n",
    "        \"framework\",\n",
    "        \"run_id\",\n",
    "        \"sprint_id\",\n",
    "        \"start_time\",\n",
    "        \"end_time\",\n",
    "        \"tokens_in\",\n",
    "        \"tokens_out\",\n",
    "        \"api_calls\",\n",
    "        \"cached_tokens\",\n",
    "        \"status\"\n",
    "    ])\n",
    "\n",
    "    invalid_runs_df = pd.DataFrame(columns=[\n",
    "        \"framework\",\n",
    "        \"run_id\",\n",
    "        \"reason\"\n",
    "    ])\n",
    "\n",
    "    # Iterate over each subdirectory in the runs directory to find each framework used\n",
    "    for framework_dir in os.listdir(runs_directory):\n",
    "        framework_path = os.path.join(runs_directory, framework_dir)\n",
    "        if os.path.isdir(framework_path):\n",
    "            # Processing each framework directory\n",
    "            for run_dir in os.listdir(framework_path):\n",
    "                run_path = os.path.join(framework_path, run_dir)\n",
    "                # loading the \"metrics.json\" file under each run directory\n",
    "                metrics_path = os.path.join(run_path, \"metrics.json\")\n",
    "                metrics_data = {}\n",
    "                if os.path.isfile(metrics_path):\n",
    "                    with open(metrics_path, 'r') as f:\n",
    "                        metrics_data = json.load(f)\n",
    "                else:\n",
    "                    # log invalid run\n",
    "                    invalid_runs_df = pd.concat([invalid_runs_df, pd.DataFrame([{\n",
    "                        \"framework\": framework_dir,\n",
    "                        \"run_id\": run_dir,\n",
    "                        \"reason\": \"metrics.json file not found\"\n",
    "                    }])], ignore_index=True)\n",
    "                    continue\n",
    "\n",
    "                # in metrics_data, we can find the \"sprints\" information under the \"steps\" key\n",
    "                # there, 'step' means 'sprint'\n",
    "                # \"steps\": [\n",
    "                #     {\n",
    "                #     \"step_number\": 1,\n",
    "                #     \"command\": \"Create a simple web application for a Student entity with name field using Python, FastAPI, and SQLite.\\n\\nRequirements:\\n- You must use the best practices for structuring a simple Python web application\\n- Use Python 3.11+ with FastAPI framework\\n- SQLite database for persistence\\n- Create Student entity with only:\\n  - name (string, required)\\n- API should return JSON responses\\n- Database schema should be created automatically on startup\",\n",
    "                #     \"duration_seconds\": 28.370058059692383,\n",
    "                #     \"success\": true,\n",
    "                #     \"retry_count\": 0,\n",
    "                #     \"hitl_count\": 0,\n",
    "                #     \"tokens_in\": 11634,\n",
    "                #     \"tokens_out\": 2897,\n",
    "                #     \"api_calls\": 6,\n",
    "                #     \"cached_tokens\": 0,\n",
    "                #     \"start_timestamp\": 1761442133,\n",
    "                #     \"end_timestamp\": 1761442161,\n",
    "                #     \"verification_status\": \"pending\"\n",
    "                #     },\n",
    "                #     ...                \n",
    "                if \"steps\" in metrics_data:\n",
    "                    for sprint in metrics_data[\"steps\"]:\n",
    "                        # add a new entry to the sprints_df\n",
    "                        sprint_id = sprint.get(\"step_number\", None)\n",
    "                        start_time = sprint.get(\"start_timestamp\", None)\n",
    "                        end_time = sprint.get(\"end_timestamp\", None)\n",
    "                        tokens_in = sprint.get(\"tokens_in\", None)\n",
    "                        tokens_out = sprint.get(\"tokens_out\", None)\n",
    "                        api_calls = sprint.get(\"api_calls\", None)\n",
    "                        cached_tokens = sprint.get(\"cached_tokens\", None)\n",
    "                        status = sprint.get(\"verification_status\", None)\n",
    "\n",
    "                        # add a new row to the dataframe\n",
    "                        sprints_df = pd.concat([sprints_df, pd.DataFrame([{\n",
    "                            \"framework\": framework_dir,\n",
    "                            \"run_id\": run_dir,\n",
    "                            \"sprint_id\": sprint_id,\n",
    "                            \"start_time\": start_time,\n",
    "                            \"end_time\": end_time,\n",
    "                            \"tokens_in\": tokens_in,\n",
    "                            \"tokens_out\": tokens_out,\n",
    "                            \"api_calls\": api_calls,\n",
    "                            \"cached_tokens\": cached_tokens,\n",
    "                            \"status\": status\n",
    "                        }])], ignore_index=True)\n",
    "\n",
    "    return sprints_df, invalid_runs_df\n",
    "\n",
    "sprints_df, invalid_runs_df = get_sprints_df()\n",
    "sprints_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f93f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_runs_df.to_csv('invalid_runs-metrics_not_found.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1664832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the number of unique runs per framework\n",
    "run_counts = sprints_df.groupby('framework')['run_id'].nunique()\n",
    "run_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the valid runs, find the sprints with the tokens in or tokens out equal to zero or NaN\n",
    "invalid_sprints_df = sprints_df[(sprints_df['tokens_in'] == 0) | (sprints_df['tokens_out'] == 0) | (sprints_df['tokens_in'].isna()) | (sprints_df['tokens_out'].isna())]\n",
    "invalid_sprints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "invalid_sprints_df.to_csv('invalid_sprints-tokens_count_zero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448cd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the unique frameworks with invalid sprints\n",
    "invalid_frameworks = invalid_sprints_df['framework'].unique()\n",
    "invalid_frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8db5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the unique runs with invalid sprints\n",
    "invalid_runs2 = invalid_sprints_df[['framework', 'run_id']].drop_duplicates()\n",
    "invalid_runs2.reset_index(drop=True, inplace=True)\n",
    "# saving the reason\n",
    "invalid_runs2['reason'] = 'Some sprint with tokens count zero or NaN'\n",
    "# save as csv\n",
    "invalid_runs2.to_csv('invalid_runs-tokens_count_zero.csv', index=False)\n",
    "invalid_runs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ffd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the unique sprints with invalid token counts\n",
    "invalid_sprint_ids = invalid_sprints_df['sprint_id'].unique()\n",
    "invalid_sprint_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the number of unique sprints per framework and run_id in the invalid_sprints_df\n",
    "invalid_sprint_counts = invalid_sprints_df.groupby(['framework', 'run_id'])['sprint_id'].nunique()\n",
    "invalid_sprint_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install matplotlib and seaborn if not already installed\n",
    "%pip install matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a frequency distribution plot showing the count of occurrences of each step_id of invalid_sprint_counts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(invalid_sprint_counts, bins=len(invalid_sprint_counts.unique()), kde=False)\n",
    "plt.title('Frequency Distribution of Invalid Sprint Counts per (Framework, Run ID)')\n",
    "plt.xlabel('Number of Invalid Sprints')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
